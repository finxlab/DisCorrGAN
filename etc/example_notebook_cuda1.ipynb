{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import copy\n",
    "import pickle\n",
    "import ml_collections\n",
    "import wandb, signatory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path as pt\n",
    "from tqdm import tqdm\n",
    "sns.set_style(\"darkgrid\")  # 원하는 스타일 선택\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration dict\n",
    "config_dir = 'configs/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    \n",
    "torch.cuda.set_device(1)\n",
    "if (config.device == \"cuda\" and torch.cuda.is_available()):\n",
    "    config.update({\"device\": \"cuda:1\"}, allow_val_change=True)    \n",
    "else:\n",
    "    config.update({\"device\": \"cpu\"}, allow_val_change=True)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/indices.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df.set_index('Date', inplace=True)\n",
    "df = df.apply(pd.to_numeric).astype(float)\n",
    "\n",
    "log_returns = np.diff(np.log(df), axis=0)\n",
    "log_returns_scaled, scalers = scaling(log_returns)\n",
    "\n",
    "# Step 4: Prepare initial prices and create rolling windows\n",
    "init_price = torch.from_numpy(np.array(df)[:-(config.n_steps), :]).float().unsqueeze(1)\n",
    "log_returns_scaled = torch.from_numpy(rolling_window(log_returns_scaled, config.n_steps)).float()\n",
    "log_returns_org = torch.from_numpy(rolling_window(log_returns, config.n_steps)).float()\n",
    "print('log_returns_scaled:', log_returns_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Return Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute cumulative log returns\n",
    "cumulative_log_returns = np.cumsum(log_returns, axis=0)\n",
    "custom_palette = sns.color_palette(\"Dark2\", 6)\n",
    "# Step 4: Create a DataFrame for cumulative log returns\n",
    "cumulative_log_returns_df = pd.DataFrame(\n",
    "    cumulative_log_returns,\n",
    "    index=df.index[1:],  # Adjust index for cumulative log returns\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "# Step 5: Plot the cumulative log return paths\n",
    "plt.figure(figsize=(14, 7))\n",
    "i = 0\n",
    "for col in cumulative_log_returns_df.columns:\n",
    "    plt.plot(cumulative_log_returns_df.index, cumulative_log_returns_df[col], label=col, color=custom_palette[i])\n",
    "    i += 1\n",
    "\n",
    "plt.title(\"Cumulative Log Return Paths of 6 Assets\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Cumulative Log Returns\", fontsize=14)\n",
    "plt.legend(title=\"Assets\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models for time series generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the data into training and validation set for the offline evaluation of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(log_returns_scaled.shape[0] * 0.7)\n",
    "\n",
    "training_data = log_returns_scaled[:train_size]\n",
    "test_data = log_returns_scaled[train_size:]\n",
    "\n",
    "train_init_price = init_price[:train_size]\n",
    "test_init_price = init_price[train_size:]\n",
    "\n",
    "training_data_org = log_returns_org[:train_size]\n",
    "test_data_org = log_returns_org[train_size:]\n",
    "\n",
    "print(\"training_data: \", training_data.shape)\n",
    "print(\"test_data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = TensorDataset(training_data)\n",
    "test_set = TensorDataset(test_data)\n",
    "\n",
    "train_dl = DataLoader(training_set, batch_size=config.batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the generator, discriminator and the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baselines.networks.discriminators import TCNDiscriminator\n",
    "from src.baselines.networks.generators import TCNGenerator\n",
    "from src.baselines.trainer import *\n",
    "\n",
    "generators = {}\n",
    "discriminators = {}\n",
    "\n",
    "for i in range(config.n_vars):\n",
    "    generators[i] = TCNGenerator(config).to(config.device)\n",
    "    discriminators[i] = TCNDiscriminator(config).to(config.device)\n",
    "trainer = GANTrainer(G=generators, D=discriminators, train_dl=train_dl, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model training\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVFIT-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = \"NEW_3_150_256_Glr_0.0002_Dlr_0.0001_hidden_dim_48_n_steps_256_corr_loss_l1_corr_weight_1.0_f_epoch_40_n_critic_2_gp_10.0_noise_3_Adam_drop_0.0_0.2_8_splitupdate_v2_corrlinear_overall_Adam0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Find the best epochs based on 100 days cumulative distribution \"\"\"\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "min_dist = float('inf')  \n",
    "best_epoch = 0\n",
    "window = 100\n",
    "\n",
    "def compute_avg_emd(real_data, fake_data, window):\n",
    "    emd = 0\n",
    "    for i in range(real_data.shape[1]):\n",
    "        real_dist = rolling_window(real_data[:, i, :].T, window).sum(axis=1).ravel()\n",
    "        fake_dist = rolling_window(fake_data[:, i, :].T, window).sum(axis=1).ravel()\n",
    "        emd += wasserstein_distance(real_dist, fake_dist)\n",
    "    return emd\n",
    "\n",
    "def load_sub_generator(file_path, config):\n",
    "    sub_gen = TCNGenerator(config)\n",
    "    sub_gen.load_state_dict(torch.load(file_path, map_location=config.device))\n",
    "    return sub_gen.to(config.device).eval()\n",
    "\n",
    "epochs_to_check = range(120, 150, 2) \n",
    "\n",
    "min_emd = [float('inf')] * config.n_vars\n",
    "best_epoch = [None] * config.n_vars\n",
    "\n",
    "real_data = training_data_org.transpose(1, 2).cpu().numpy()\n",
    "\n",
    "noise = torch.randn(real_data.shape[0], config.noise_dim, config.n_steps).to(config.device)\n",
    "\n",
    "for epoch in epochs_to_check:\n",
    "    for i in range(config.n_vars):\n",
    "        file_path = os.path.join(f'./results/models/{full_name}/', f\"Generator_{epoch}_var_{i}.pt\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        sub_gen = load_sub_generator(file_path, config)        \n",
    "        with torch.no_grad():\n",
    "            fake = sub_gen(noise)  \n",
    "        fake_data = inverse_scaling(fake, scalers, i) \n",
    "        emd_val = compute_avg_emd(real_data[:, i:i+1, :], fake_data, window)\n",
    "        if emd_val < min_emd[i]:\n",
    "            min_emd[i] = emd_val\n",
    "            best_epoch[i] = epoch\n",
    "    \n",
    "    print(f\"Epoch {epoch}: best_epoch = {best_epoch}, min_emd = {min_emd}\")\n",
    "\n",
    "print(\"\\n--- 최종 결과: 각 서브 생성자별 Best Epoch ---\")\n",
    "for i in range(config.n_vars):\n",
    "    print(f\"SubGen {i}: best epoch = {best_epoch[i]}, EMD = {min_emd[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = training_data_org.transpose(1, 2).cpu().numpy()\n",
    "\n",
    "fake_series_list = []\n",
    "for i in range(config.n_vars):    \n",
    "    best_ep = best_epoch[i] \n",
    "    file_path = os.path.join(f'./results/models/{full_name}/', f\"Generator_{best_ep}_var_{i}.pt\")\n",
    "    \n",
    "    sub_gen = load_sub_generator(file_path, config)\n",
    "    with torch.no_grad():\n",
    "        fake = sub_gen(noise)\n",
    "    \n",
    "    fake_data_i = inverse_scaling(fake, scalers, i)\n",
    "    fake_data_i = torch.tensor(fake_data_i, device=config.device)\n",
    "    \n",
    "    fake_series_list.append(fake_data_i)\n",
    "\n",
    "fake_data = torch.cat(fake_series_list, dim=1)\n",
    "fake_data = fake_data.cpu().numpy()\n",
    "print(\"다변량 시계열 데이터의 shape:\", fake_data.shape)\n",
    "\n",
    "np.save('fake_data.npy', fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Visualize the distribution of the real and fake data \"\"\"\n",
    "fake_list = [fake_data[:, i, :] for i in range(fake_data.shape[1])]\n",
    "real_list = [real_data[:, i, :] for i in range(real_data.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.eval_gen_quality.gen_quality import *\n",
    "windows = [1, 5, 20, 100]\n",
    "\n",
    "plot_distribution_comparison(real_list, fake_list, n_vars=config.n_vars, windows=windows)\n",
    "plot_distribution_comparison_vertical(real_list, fake_list, n_vars=config.n_vars, windows=windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dist = calculate_distribution_scores(real_list, fake_list, n_vars=config.n_vars, windows= windows)\n",
    "# df_skew_diff, df_kurt_diff = calculate_skew_kurtosis(\n",
    "#     real_list, fake_list, windows\n",
    "# )\n",
    "\n",
    "# print(\"\\n윈도우별 EMD:\")\n",
    "# print(results_dist['EMD'])\n",
    "\n",
    "# print(\"\\n윈도우별 KS:\")\n",
    "# print(results_dist['KS'])\n",
    "\n",
    "# print(\"\\n윈도우별 Skewness Difference:\") \n",
    "# print(df_skew_diff)\n",
    "\n",
    "# print(\"\\n윈도우별 Kurtosis Difference:\")\n",
    "# print(df_kurt_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_comparison(real_list, fake_list, n_vars=config.n_vars, lags=100)\n",
    "plot_acf_comparison_vertical(real_list, fake_list, n_vars=config.n_vars, lags=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_scores, avg_scores = calculate_acf_score(real_list, fake_list, lags=40, loss_type='mse')\n",
    "\n",
    "print(\"=== ACF Scores (per group) ===\")\n",
    "for group_name, transform_scores in acf_scores.items():\n",
    "    print(f\"{group_name}:\")\n",
    "    for transform_title, val in transform_scores.items():\n",
    "        print(f\"  - {transform_title}: loss={val}\")\n",
    "\n",
    "print(\"\\n=== Overall Average Scores ===\")\n",
    "for transform_title, mean_of_means in avg_scores.items():\n",
    "    print(f\"{transform_title}: mean of means={mean_of_means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mean_corr = ccf_mean(np.transpose(real_data, (0, 2, 1)))\n",
    "fake_mean_corr = ccf_mean(np.transpose(fake_data, (0, 2, 1)))\n",
    "\n",
    "loss_ccf = ccf_loss(real_mean_corr, fake_mean_corr, loss_type='mae')\n",
    "\n",
    "print(\"[Correlation Loss - MAE]\")\n",
    "print(f\"Loss: {loss_ccf}\")\n",
    "    \n",
    "plot_ccf_heatmap(real_mean_corr, \"Real\", annot=False)\n",
    "plot_ccf_heatmap(fake_mean_corr, \"Fake\", annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mean_ccf_lag = ccf_lag_mean(np.transpose(real_data, (0, 2, 1)), lag=10)\n",
    "fake_mean_ccf_lag = ccf_lag_mean(np.transpose(fake_data, (0, 2, 1)), lag=10)\n",
    "\n",
    "loss_ccf_lag = ccf_lag_loss(real_mean_ccf_lag, fake_mean_ccf_lag, loss_type='mae')\n",
    "\n",
    "print(\"[Partial CCF Loss - MAE]\")\n",
    "print(f\"Loss: {loss_ccf_lag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_scores, overall_mean = leverage_effect_loss(\n",
    "    real_list, \n",
    "    fake_list, \n",
    "    lags=40, \n",
    "    loss_type='mse'\n",
    ")\n",
    "\n",
    "print(\"\\n=== Leverage Effect Loss (Mean vs. Mean) ===\")\n",
    "for group, loss in leverage_scores.items():\n",
    "    print(f\"{group}: {loss}\")\n",
    "print(f\"Overall Mean Loss: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_labels = ['Dow Jones', 'Nasdaq', 'JP Morgan', 'Hang Seng', 'Gold', 'WTI']\n",
    "plot_best_generated_sample(fake_data, real_mean_corr, asset_labels)\n",
    "plot_real_cumulative_log_returns(df, asset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the performance of our model by first generating the price process, apply the prespecified trading strategies and compare the resulting PnL process using the real and fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.eval_portfolio.strategies import log_return_to_price\n",
    "\n",
    "eval_size = real_data.shape[0]\n",
    "\n",
    "fake_data_torch = torch.from_numpy(fake_data).float().transpose(1, 2)\n",
    "real_data_torch = torch.from_numpy(real_data).float().transpose(1, 2)\n",
    "\n",
    "test_init_price = train_init_price\n",
    "test_init_price[:] = 100\n",
    "\n",
    "fake_prices = log_return_to_price(fake_data_torch[:eval_size], test_init_price[:eval_size])\n",
    "real_prices = log_return_to_price(real_data_torch[:eval_size], test_init_price[:eval_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.eval_portfolio.strategies import log_return_to_price\n",
    "from src.evaluation.eval_portfolio.summary import *\n",
    "\n",
    "config_dir = 'src/evaluation/eval_portfolio/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    eval_config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "\n",
    "all_positive = (fake_prices > 0).all()\n",
    "if not all_positive:\n",
    "    raise ValueError(\"Sanity Check Failed: Some fake prices are not positive.\")\n",
    "\n",
    "res_dict = {\n",
    "    \"var_abs_mean\": 0.,\n",
    "    \"var_rel_mean\": 0.,\n",
    "    \"es_abs_mean\": 0.,\n",
    "    \"es_rel_mean\": 0.,\n",
    "}\n",
    "\n",
    "num_strat = 4  # 전략 개수\n",
    "\n",
    "with torch.no_grad():\n",
    "    for strat_name in ['equal_weight', 'mean_reversion', 'trend_following', 'vol_trading']:                    \n",
    "        subres_dict, pnl_real, pnl_fake = full_evaluation(fake_prices, real_prices, eval_config, strat_name=strat_name)        \n",
    "        filtered_means = {\n",
    "            k: round(v, 4) for k, v in subres_dict.items() if '_mean' in k\n",
    "        }\n",
    "        print(f\"{strat_name}: {filtered_means}\")        \n",
    "        # 전략별 plot 호출\n",
    "        plot_cumulative_pnl_quantiles(pnl_real, pnl_fake, strat_name)\n",
    "\n",
    "        for k in res_dict:            \n",
    "            res_dict[k] += subres_dict[k] / num_strat\n",
    "\n",
    "for k, v in res_dict.items():\n",
    "    print(k, round(v, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
